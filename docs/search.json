[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA Quarto File",
    "section": "",
    "text": "This is the initial Exploratory Data Analysis file which will examine the Diabetes Health Indicators data set.\n\n\n\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) conducts yearly phone surveys in the United States. The surveys include questions for Americans about their health status and care choices. Our data set is a subset of the BRFSS survey calls from 2015 which focus on diabetes-related survey responses.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiabetes_binary\nHighBP\nHighChol\nCholCheck\nBMI\nSmoker\nStroke\n\n\n\n\nClass\nClass\nClass\nClass\nNum\nClass\nClass\n\n\n0\n0\n0\n0\n\n0\n0\n\n\n1\n1\n1\n1\n\n1\n1\n\n\n\n\nDiabetes Survey Response variables - columns and their type.\n\n\nHeartDiseaseorAngina\nPhysActivty\nFruits\n\n\n\n\nClass\nClass\nClass\n\n\n0\n0\n0\n\n\n1\n1\n1\n\n\n\n\n\n\nStart by activiting the necessary packages\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n\nInsert comments on which predictors\n\n\ndiabetes &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nspec(diabetes)\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)\n\n\n\n\n\nThe output above lists all the variables/columns associated with the BRFSS binary indicators dataset from 2015. See below for an explanation of the variables in question:\n\nDiabetes_binary: An assessment of diabetes status of the individual respondent with 3 levels:\n\n\n\n0\n1\n2\n\n\n\n\nNo Diabetes\nPre-Diabetes\nDiabetes\n\n\n\n\nClean up data - identify NA’ed rows. I would like to identify if there are any columns with NA values.\n\n\nNA_vec &lt;- c(seq_along(diabetes))\nnames(NA_vec) &lt;- names(diabetes)\n\nfor (i in seq_along(diabetes)) {\n  NA_vec[i] &lt;- sum(is.na(diabetes[i]))\n}\n\nNA_vec\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\n\nThere are no NAs in any of the columns, so no omitting of rows for that particular reason is required.\n\n\nOne unique challenge or assessment of this data set is that all variables except for BMI are binary and/or classes. They are all double/numeric type columns with integers denoting a factored response to an associated question, whether it be a binary Yes/No, or a grouped category like education level (with levels 1-6) With that said, we can get som summary statistics and distribution information around the only continuous variable: BMI.\n\n\nb &lt;- ggplot(data = diabetes, aes(x=BMI))\nb + geom_histogram(binwidth = 5) +\n  labs(title = \"BMI Histogram\")\n\n\n\n\n\n\n\n\n\nSummary Statistics for BMI:\n\n\nsummary(diabetes$BMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   24.00   27.00   28.38   31.00   98.00 \n\n\n\nThe maximum identification of 98 is helpful for this exercise, because it’s difficult to see the outlier values from the histogram.\n\n\n\n\n\n\nTo support the model development, I will convert the target variable: Diabetes_binary to a factor column with status of “No”, “Pre”, “Diabetes”\n\n\ndiab2 &lt;- diabetes |&gt;\n  mutate(DiabetesStatus = \n           ifelse(Diabetes_binary == 0, \"No\",\n                  ifelse(Diabetes_binary == 1, \"Yes\",\n                         \"ERROR\")))\ndiab2$DiabetesStatus &lt;- as.factor(diab2$DiabetesStatus)\n\n(diab2)\n\n# A tibble: 253,680 × 23\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 16 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;,\n#   DiabetesStatus &lt;fct&gt;\n\n\n\nViewing combination of variables\n\n\npairs(~ Age + Education + Income, data = diab2)\n\n\n\n\n\n\n\n\n\nMore plots\n\n\ndistSum &lt;- diab2 |&gt;\n  group_by(Age) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(distSum, aes(x=Age, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nInc_Prop &lt;- diab2 |&gt;\n  group_by(Income) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(Inc_Prop, aes(x=Income, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nInc_Prop &lt;- diab2 |&gt;\n  group_by(Education) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(Inc_Prop, aes(x=Education, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nBMI_Prop &lt;- diab2 |&gt;\n  group_by(BMI) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(BMI_Prop, aes(x=BMI, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nsaveRDS(diab2, file = \"diab2.rds\")\n\n\n\n\nClick here for the Modeling Page"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling Quarto File",
    "section": "",
    "text": "Modeling Quarto File\n\nThis is the Modeling file which will be used to construct and evaluate different model fits for predictive modeling of Diabetes Health Indicators.\n\n\nStart by activiting the necessary packages\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(ranger)\nlibrary(Metrics)\n\ndiabmodel &lt;- readRDS(\"diab2.rds\")\n\n\nPartition the data set into training & test sets\n\n\nset.seed(90)\ntrainIndex &lt;- createDataPartition(diabmodel$DiabetesStatus, p = 0.7, list = FALSE)\ndiabTrain &lt;- diabmodel[trainIndex, ]\ndiabTest &lt;- diabmodel[-trainIndex, ]\n\n\nBegin modeling:\n\n\nCreate the training object\n\n\ntrctrl &lt;- trainControl(method = \"cv\", number = 5, classProbs = TRUE,\n                       summaryFunction = mnLogLoss)\nset.seed(56)\n\n\nLogistic Regression Models\n\nAge, BMI, HighBP, HighChol\n\nStarting with a model only dependent upon age\n\n\n(glmFit1 &lt;- train(DiabetesStatus ~ Age*BMI*HighBP*HighChol,\n                 data = diabTrain,\n                 method = \"glm\",\n                 metric = \"logLoss\",\n                 trControl=trctrl))\n\nGeneralized Linear Model \n\n177577 samples\n     4 predictor\n     2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142061, 142062, 142061, 142062, 142062 \nResampling results:\n\n  logLoss  \n  0.3400812\n\n\n\n\nAge, BMI, Education, Income, Physical Activity, Smoker\n\nNext use a model incorporating age & BMI, with interaction effects:\n\n\n(glmFit2 &lt;- train(DiabetesStatus ~\n                    Age*BMI*Education*Income*PhysActivity*Smoker,\n                 data = diabTrain,\n                 method = \"glm\",\n                 metric = \"logLoss\",\n                 trControl=trctrl))\n\nGeneralized Linear Model \n\n177577 samples\n     6 predictor\n     2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142061, 142062, 142061, 142062, 142062 \nResampling results:\n\n  logLoss  \n  0.3527875\n\n\n\n\nEducation, Income, High BP, High Cholesterol\n\nFinally, a model incorporating Education, Income, and their interaction effects:\n\n\n(glmFit3 &lt;- train(DiabetesStatus ~\n                    Education*Income*HighBP*HighChol*Sex,\n                 data = diabTrain,\n                 method = \"glm\",\n                 metric = \"logLoss\",\n                 trControl=trctrl))\n\nGeneralized Linear Model \n\n177577 samples\n     5 predictor\n     2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142061, 142061, 142062, 142062, 142062 \nResampling results:\n\n  logLoss  \n  0.3515092\n\n\n\n\n\nClassification Tree\n\n(treeFit1 &lt;- train(DiabetesStatus ~\nBMI*GenHlth*Smoker*Education*Income*Age*PhysActivity,\n                  data = diabmodel,\n                  method = \"rpart\",\n                  trControl=trctrl,\n                  preProcess = c(\"center\", \"scale\"),\n                  tuneGrid = data.frame(cp = seq(0, 0.1,\n                                                 by = 0.001)),\n                  metric = \"logLoss\"))\n\nCART \n\n253680 samples\n     7 predictor\n     2 classes: 'No', 'Yes' \n\nPre-processing: centered (127), scaled (127) \nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 202944, 202944, 202943, 202945, 202944 \nResampling results across tuning parameters:\n\n  cp     logLoss  \n  0.000  0.4829028\n  0.001  0.3496636\n  0.002  0.3496728\n  0.003  0.3714866\n  0.004  0.3929922\n  0.005  0.4037509\n  0.006  0.4037509\n  0.007  0.4037509\n  0.008  0.4037509\n  0.009  0.4037509\n  0.010  0.4037509\n  0.011  0.4037509\n  0.012  0.4037509\n  0.013  0.4037509\n  0.014  0.4037509\n  0.015  0.4037509\n  0.016  0.4037509\n  0.017  0.4037509\n  0.018  0.4037509\n  0.019  0.4037509\n  0.020  0.4037509\n  0.021  0.4037509\n  0.022  0.4037509\n  0.023  0.4037509\n  0.024  0.4037509\n  0.025  0.4037509\n  0.026  0.4037509\n  0.027  0.4037509\n  0.028  0.4037509\n  0.029  0.4037509\n  0.030  0.4037509\n  0.031  0.4037509\n  0.032  0.4037509\n  0.033  0.4037509\n  0.034  0.4037509\n  0.035  0.4037509\n  0.036  0.4037509\n  0.037  0.4037509\n  0.038  0.4037509\n  0.039  0.4037509\n  0.040  0.4037509\n  0.041  0.4037509\n  0.042  0.4037509\n  0.043  0.4037509\n  0.044  0.4037509\n  0.045  0.4037509\n  0.046  0.4037509\n  0.047  0.4037509\n  0.048  0.4037509\n  0.049  0.4037509\n  0.050  0.4037509\n  0.051  0.4037509\n  0.052  0.4037509\n  0.053  0.4037509\n  0.054  0.4037509\n  0.055  0.4037509\n  0.056  0.4037509\n  0.057  0.4037509\n  0.058  0.4037509\n  0.059  0.4037509\n  0.060  0.4037509\n  0.061  0.4037509\n  0.062  0.4037509\n  0.063  0.4037509\n  0.064  0.4037509\n  0.065  0.4037509\n  0.066  0.4037509\n  0.067  0.4037509\n  0.068  0.4037509\n  0.069  0.4037509\n  0.070  0.4037509\n  0.071  0.4037509\n  0.072  0.4037509\n  0.073  0.4037509\n  0.074  0.4037509\n  0.075  0.4037509\n  0.076  0.4037509\n  0.077  0.4037509\n  0.078  0.4037509\n  0.079  0.4037509\n  0.080  0.4037509\n  0.081  0.4037509\n  0.082  0.4037509\n  0.083  0.4037509\n  0.084  0.4037509\n  0.085  0.4037509\n  0.086  0.4037509\n  0.087  0.4037509\n  0.088  0.4037509\n  0.089  0.4037509\n  0.090  0.4037509\n  0.091  0.4037509\n  0.092  0.4037509\n  0.093  0.4037509\n  0.094  0.4037509\n  0.095  0.4037509\n  0.096  0.4037509\n  0.097  0.4037509\n  0.098  0.4037509\n  0.099  0.4037509\n  0.100  0.4037509\n\nlogLoss was used to select the optimal model using the smallest value.\nThe final value used for the model was cp = 0.001.\n\n\n\n\nRandom Forest\n\n(treeFit2 &lt;- train(DiabetesStatus ~ .,\n                  data = diabmodel,\n                  method = \"ranger\",\n                  tuneGrid = expand.grid(\n                    mtry = 2,\n                    splitrule = \"extratrees\",\n                    min.node.size=100),\n                  trControl=trctrl,\n                  preProcess = c(\"center\", \"scale\"),\n                  metric = \"logLoss\",\n                  num.trees = 100))\n\nRandom Forest \n\n253680 samples\n    22 predictor\n     2 classes: 'No', 'Yes' \n\nPre-processing: centered (22), scaled (22) \nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 202944, 202943, 202944, 202945, 202944 \nResampling results:\n\n  logLoss   \n  0.07103378\n\nTuning parameter 'mtry' was held constant at a value of 2\nTuning\n parameter 'splitrule' was held constant at a value of extratrees\n\nTuning parameter 'min.node.size' was held constant at a value of 100\n\n\n\nUsing this random forest method and the ‘ranger’ package which randomly select supporting parameters, the value of ‘mtry’ for a random forest model which minimizes logLoss value is mtry = 2.\n\n\n\nFinal Model Selection\n\nLet’s select the best model based on using the various training methodologies on the test set. The three models in question are the best results from the Logistic Regression, Classification Tree, and Random Forest models. For Logistic Regression, the lowest logLoss function result was the formula analyzing Age, BMI, High Blood Pressure, High Cholesterol, and their interaction effects. For Classification Tree - with predictors of BMI, General Health, and their interaction effects, the lowest logLoss function result was associated with the cp (complexity parameter) of 0. For The Random Forest, the lowest logLoss function result was associated with an mtry of 2.\n\n\nFirst, we need to predict values using each model on the test set\n\n\nGLM Prediction\n\nhead(glmpred &lt;- predict(glmFit1, diabTest, type = \"prob\"))\n\n         No        Yes\n1 0.5283996 0.47160036\n2 0.7481845 0.25181547\n3 0.8409993 0.15900073\n4 0.6222792 0.37772078\n5 0.9685681 0.03143189\n6 0.9287960 0.07120399\n\n\n\n(logLoss(diabmodel$Diabetes_binary, glmpred$Yes))\n\n[1] 0.4841449\n\n\n\n\nClassification Tree Prediction\n\nhead(ctpred &lt;- predict(treeFit1, diabTest, type = \"prob\", cp = 0.001))\n\n         No        Yes\n1 0.4286344 0.57136564\n2 0.5613505 0.43864953\n3 0.7515312 0.24846878\n4 0.7515312 0.24846878\n5 0.9363272 0.06367278\n6 0.9363272 0.06367278\n\n\n\n(logLoss(diabmodel$Diabetes_binary, ctpred$Yes))\n\n[1] 0.4576252\n\n\n\n\nRandom Forest Prediction\n\nhead(rfpred &lt;- predict(treeFit2, diabTest, type = \"prob\"))\n\n         No        Yes\n1 0.8944415 0.10555849\n2 0.9009731 0.09902686\n3 0.9644001 0.03559992\n4 0.8894971 0.11050286\n5 0.9780418 0.02195821\n6 0.9302189 0.06978107\n\n\n\nlogLoss(diabmodel$Diabetes_binary, rfpred$Yes)\n\n[1] 0.6738778\n\n\n\n\n\nModel Selection\n\nThe final logLoss results from each of the 3 best iterations of each model, result in the following:\n\n\n\n\nModel\nlogLoss\n\n\n\n\nGLM\n0.4841\n\n\nClassification Tree\n0.4576\n\n\nRandom Forest\n0.6739\n\n\n\n\n\nFunction for Prediction\n\nPrior to populating the API file, I want to develop a function that will take in predictor values for arguments and produce a predicted value.\n\n\n#BMI*GenHlth*Smoker*Education*Income*Age*PhysActivity\n(predvec &lt;- data.frame(BMI = 25, GenHlth = 3, Smoker = 1,\n                       Education = 3, Income = 4, Age = 9,\n                       PhysActivity = 0))\n\n  BMI GenHlth Smoker Education Income Age PhysActivity\n1  25       3      1         3      4   9            0\n\n\n\npredict(treeFit1, newdata = predvec, type = \"prob\")\n\n         No        Yes\n1 0.9363272 0.06367278\n\n\n\nNow, using the structure above, I’ll develop a function building the newdata dataframe from the predictor variables specified.\n\n\npredct &lt;- function(BMI = 25, GenHlth = 3, Smoker = 1,\n                     Education = 4, Income = 5, Age = 8,\n                     PhysActivity = 1) {\n  pred_df &lt;- data.frame(BMI = BMI, GenHlth = GenHlth,\n                        Smoker = Smoker, Education = Education,\n                        Income = Income, Age = Age,\n                        PhysActivity = PhysActivity)\n  predict(treeFit1, newdata = pred_df, type = \"prob\")\n}\n\n\npredct(50, 2, 0, 6, 8, 10, 0)\n\n         No       Yes\n1 0.7515312 0.2484688\n\n\n\n\nFunction for API Query\n\nUnfortunately, the best model (by logLoss value) consumes quite a few resources, and generating the model in an API file, hosted by a docker container, caused the docker image to time out before the container became active/usable. To ensure the exercise can be completed through a docker-based API, I will use a simpler model: GLM with only 2 predictors: Age & Income.\n\n\n(glmFit4 &lt;- train(DiabetesStatus ~ Age*Income,\n                  data = diabTrain,\n                  method = \"glm\",\n                  metric = \"logLoss\",\n                  trControl=trctrl))\n\nGeneralized Linear Model \n\n177577 samples\n     2 predictor\n     2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 142063, 142061, 142061, 142062, 142061 \nResampling results:\n\n  logLoss  \n  0.3767495\n\n\n\n#Function for simplified GLM model\npredglm &lt;- function(Age = 8, Income = 5) {\n  pred_df &lt;- data.frame(Age = as.numeric(Age),\n                        Income = as.numeric(Income))\n  predict(glmFit4, newdata = pred_df, type = \"prob\")\n}\n\n\npredglm(Age = 11, Income = 2)\n\n         No       Yes\n1 0.6966121 0.3033879\n\n\n\n\nLink to EDA Site:\nClick here for the EDA Page"
  },
  {
    "objectID": "EDA.html#introduction-to-data",
    "href": "EDA.html#introduction-to-data",
    "title": "EDA Quarto File",
    "section": "",
    "text": "The Behavioral Risk Factor Surveillance System (BRFSS) conducts yearly phone surveys in the United States. The surveys include questions for Americans about their health status and care choices. Our data set is a subset of the BRFSS survey calls from 2015 which focus on diabetes-related survey responses.\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiabetes_binary\nHighBP\nHighChol\nCholCheck\nBMI\nSmoker\nStroke\n\n\n\n\nClass\nClass\nClass\nClass\nNum\nClass\nClass\n\n\n0\n0\n0\n0\n\n0\n0\n\n\n1\n1\n1\n1\n\n1\n1\n\n\n\n\nDiabetes Survey Response variables - columns and their type.\n\n\nHeartDiseaseorAngina\nPhysActivty\nFruits\n\n\n\n\nClass\nClass\nClass\n\n\n0\n0\n0\n\n\n1\n1\n1\n\n\n\n\n\n\nStart by activiting the necessary packages\n\n\nlibrary(tidyverse)\nlibrary(ggplot2)\n\n\nInsert comments on which predictors\n\n\ndiabetes &lt;- read_csv(\"diabetes_binary_health_indicators_BRFSS2015.csv\")\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nspec(diabetes)\n\ncols(\n  Diabetes_binary = col_double(),\n  HighBP = col_double(),\n  HighChol = col_double(),\n  CholCheck = col_double(),\n  BMI = col_double(),\n  Smoker = col_double(),\n  Stroke = col_double(),\n  HeartDiseaseorAttack = col_double(),\n  PhysActivity = col_double(),\n  Fruits = col_double(),\n  Veggies = col_double(),\n  HvyAlcoholConsump = col_double(),\n  AnyHealthcare = col_double(),\n  NoDocbcCost = col_double(),\n  GenHlth = col_double(),\n  MentHlth = col_double(),\n  PhysHlth = col_double(),\n  DiffWalk = col_double(),\n  Sex = col_double(),\n  Age = col_double(),\n  Education = col_double(),\n  Income = col_double()\n)\n\n\n\n\n\nThe output above lists all the variables/columns associated with the BRFSS binary indicators dataset from 2015. See below for an explanation of the variables in question:\n\nDiabetes_binary: An assessment of diabetes status of the individual respondent with 3 levels:\n\n\n\n0\n1\n2\n\n\n\n\nNo Diabetes\nPre-Diabetes\nDiabetes\n\n\n\n\nClean up data - identify NA’ed rows. I would like to identify if there are any columns with NA values.\n\n\nNA_vec &lt;- c(seq_along(diabetes))\nnames(NA_vec) &lt;- names(diabetes)\n\nfor (i in seq_along(diabetes)) {\n  NA_vec[i] &lt;- sum(is.na(diabetes[i]))\n}\n\nNA_vec\n\n     Diabetes_binary               HighBP             HighChol \n                   0                    0                    0 \n           CholCheck                  BMI               Smoker \n                   0                    0                    0 \n              Stroke HeartDiseaseorAttack         PhysActivity \n                   0                    0                    0 \n              Fruits              Veggies    HvyAlcoholConsump \n                   0                    0                    0 \n       AnyHealthcare          NoDocbcCost              GenHlth \n                   0                    0                    0 \n            MentHlth             PhysHlth             DiffWalk \n                   0                    0                    0 \n                 Sex                  Age            Education \n                   0                    0                    0 \n              Income \n                   0 \n\n\n\nThere are no NAs in any of the columns, so no omitting of rows for that particular reason is required.\n\n\nOne unique challenge or assessment of this data set is that all variables except for BMI are binary and/or classes. They are all double/numeric type columns with integers denoting a factored response to an associated question, whether it be a binary Yes/No, or a grouped category like education level (with levels 1-6) With that said, we can get som summary statistics and distribution information around the only continuous variable: BMI.\n\n\nb &lt;- ggplot(data = diabetes, aes(x=BMI))\nb + geom_histogram(binwidth = 5) +\n  labs(title = \"BMI Histogram\")\n\n\n\n\n\n\n\n\n\nSummary Statistics for BMI:\n\n\nsummary(diabetes$BMI)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  12.00   24.00   27.00   28.38   31.00   98.00 \n\n\n\nThe maximum identification of 98 is helpful for this exercise, because it’s difficult to see the outlier values from the histogram.\n\n\n\n\n\n\nTo support the model development, I will convert the target variable: Diabetes_binary to a factor column with status of “No”, “Pre”, “Diabetes”\n\n\ndiab2 &lt;- diabetes |&gt;\n  mutate(DiabetesStatus = \n           ifelse(Diabetes_binary == 0, \"No\",\n                  ifelse(Diabetes_binary == 1, \"Yes\",\n                         \"ERROR\")))\ndiab2$DiabetesStatus &lt;- as.factor(diab2$DiabetesStatus)\n\n(diab2)\n\n# A tibble: 253,680 × 23\n   Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n             &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1               0      1        1         1    40      1      0\n 2               0      0        0         0    25      1      0\n 3               0      1        1         1    28      0      0\n 4               0      1        0         1    27      0      0\n 5               0      1        1         1    24      0      0\n 6               0      1        1         1    25      1      0\n 7               0      1        0         1    30      1      0\n 8               0      1        1         1    25      1      0\n 9               1      1        1         1    30      1      0\n10               0      0        0         1    24      0      0\n# ℹ 253,670 more rows\n# ℹ 16 more variables: HeartDiseaseorAttack &lt;dbl&gt;, PhysActivity &lt;dbl&gt;,\n#   Fruits &lt;dbl&gt;, Veggies &lt;dbl&gt;, HvyAlcoholConsump &lt;dbl&gt;, AnyHealthcare &lt;dbl&gt;,\n#   NoDocbcCost &lt;dbl&gt;, GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;,\n#   DiffWalk &lt;dbl&gt;, Sex &lt;dbl&gt;, Age &lt;dbl&gt;, Education &lt;dbl&gt;, Income &lt;dbl&gt;,\n#   DiabetesStatus &lt;fct&gt;\n\n\n\nViewing combination of variables\n\n\npairs(~ Age + Education + Income, data = diab2)\n\n\n\n\n\n\n\n\n\nMore plots\n\n\ndistSum &lt;- diab2 |&gt;\n  group_by(Age) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(distSum, aes(x=Age, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nInc_Prop &lt;- diab2 |&gt;\n  group_by(Income) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(Inc_Prop, aes(x=Income, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nInc_Prop &lt;- diab2 |&gt;\n  group_by(Education) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(Inc_Prop, aes(x=Education, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nBMI_Prop &lt;- diab2 |&gt;\n  group_by(BMI) |&gt;\n  summarize(propDiabetes = mean(Diabetes_binary),\n            n = n()) |&gt;\n  ungroup()\nggplot(BMI_Prop, aes(x=BMI, y=propDiabetes)) +\n  geom_point(stat = \"identity\", aes(size = n))\n\n\n\n\n\n\n\n\n\nsaveRDS(diab2, file = \"diab2.rds\")\n\n\n\n\nClick here for the Modeling Page"
  }
]